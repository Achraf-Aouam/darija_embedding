{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arabic_reshaper and python-bidi found. RTL display enabled.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import regex as re # Make sure regex is imported if not already\n",
    "from gensim.models import Word2Vec\n",
    "from tokenizers import Tokenizer\n",
    "import unicodedata\n",
    "# Optional: For RTL display in terminal/output\n",
    "try:\n",
    "    import arabic_reshaper\n",
    "    from bidi.algorithm import get_display\n",
    "    RTL_DISPLAY_AVAILABLE = True\n",
    "    print(\"arabic_reshaper and python-bidi found. RTL display enabled.\")\n",
    "except ImportError:\n",
    "    RTL_DISPLAY_AVAILABLE = False\n",
    "    print(\"Warning: arabic_reshaper or python-bidi not found. RTL display might not be optimal.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "WORD2VEC_MODEL_PATH = '/teamspace/studios/this_studio/darija_word2vec_bpe_sg_ns.model'\n",
    "\n",
    "# ==============================================================================\n",
    "# PASTE YOUR PREPROCESSING FUNCTION DEFINITIONS HERE\n",
    "# Make sure the following functions (and ARABIZI_TO_ARABIC_MAP) are defined\n",
    "# in cells ABOVE this script in your notebook:\n",
    "#\n",
    "# 1. ARABIZI_TO_ARABIC_MAP = { ... }\n",
    "# 2. def clean_text_initial(text: str) -> str: ...\n",
    "# 3. def arabize_text(text: str) -> str: ...\n",
    "# 4. def normalize_arabic_text(text: str) -> str: ...\n",
    "#\n",
    "# (The script uses a simplified final clean, so clean_text_final is not strictly required here\n",
    "# unless your other functions depend on it in a way not covered)\n",
    "# =============================================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "ARABIZI_TO_ARABIC_MAP = {\n",
    "    # Digits (ensure these are processed before any general digit removal)\n",
    "    '2': 'ء', '3': 'ع', '4': 'غ', '6': 'ط', '8': 'ق', # Added some other common ones\n",
    "    '7': 'ح', '5': 'خ', '9': 'ق', # 9 can be ق or ص, user asked for ق, but ص is also common. Let's use ق as requested.\n",
    "                                # The user's original request had '9' -> 'ق'. I'll stick to that. '5' -> 'خ'\n",
    "    # Common multi-character sequences (longest first for correct replacement)\n",
    "    'ch': 'ش', 'sh': 'ش', 'kh': 'خ', 'gh': 'غ',\n",
    "    'th': 'ث', 'dh': 'ذ', 'ou': 'و', 'oo': 'و',\n",
    "    # Single letters (ensure input text is lowercased before this)\n",
    "    'a': 'ا', 'b': 'ب', 'c': 'س', # 'c' can be tricky, 'س' is a common default\n",
    "    'd': 'د', 'e': 'ي', # 'e' often like 'i' or kasra, 'ي' is a placeholder. Can also be 'ا'.\n",
    "    'f': 'ف', 'g': 'ڭ', # Moroccan Gaf. normalize_arabic can convert ڭ to ك or ج later if needed.\n",
    "    'h': 'ه', 'i': 'ي', 'j': 'ج', 'k': 'ك', 'l': 'ل', 'm': 'م',\n",
    "    'n': 'ن', 'o': 'و', 'p': 'ب', # 'پ' is not standard, so 'ب'\n",
    "    'q': 'ق', 'r': 'ر', 's': 'س',\n",
    "    't': 'ت', 'u': 'و', 'v': 'ف', # 'ڤ' is not standard, so 'ف'\n",
    "    'w': 'و', 'x': 'كس', 'y': 'ي', 'z': 'ز',\n",
    "}\n",
    "# # Add user's specific request for 9->ق\n",
    "# ARABIZI_TO_ARABIC_MAP['9'] = 'ق'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text_initial(text: str) -> str:\n",
    "    \"\"\"Performs initial cleaning of the text.\"\"\"\n",
    "    # Remove email addresses\n",
    "    text = re.sub(r'\\S+@\\S+', ' ', text)\n",
    "    # Remove URLs\n",
    "    text = re.sub(r'https?://\\S+|www\\.\\S+', ' ', text)\n",
    "    # Remove file markup like [[File:…]]\n",
    "    text = re.sub(r'\\[\\[File:[^\\]]*\\]\\]', ' ', text)\n",
    "    # Remove other generic wiki-like markups (e.g., [[...]], but not [[word]])\n",
    "    # This regex looks for markups with colons or pipes, common in metadata\n",
    "    text = re.sub(r'\\[\\[(?:[^\\]]*:|[^\\]]*\\|[^\\]]*)\\]\\]', ' ', text)\n",
    "    # Remove simple [[markup]] if it's not just a word\n",
    "    text = re.sub(r'\\[\\[([^\\]]{20,})\\]\\]', ' ', text) # Example: if content is too long\n",
    "    # Remove HTML tags\n",
    "    text = re.sub(r'<.*?>', ' ', text)\n",
    "    # Remove script-mismatches (e.g., \"100px\")\n",
    "    text = re.sub(r'\\b\\d+px\\b', ' ', text)\n",
    "    # Normalize Unicode to NFKC form for consistency\n",
    "    text = unicodedata.normalize('NFKC', text)\n",
    "    # Normalize whitespace early\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def arabize_text(text: str) -> str:\n",
    "    \"\"\"Converts Arabizi (Latin script Darija with numbers) to Arabic script.\"\"\"\n",
    "    text = text.lower() # Important for consistent mapping\n",
    "\n",
    "    # Create a list of keys sorted by length (descending) to handle multi-char keys first\n",
    "    sorted_keys = sorted(ARABIZI_TO_ARABIC_MAP.keys(), key=len, reverse=True)\n",
    "\n",
    "    for key in sorted_keys:\n",
    "        text = text.replace(key, ARABIZI_TO_ARABIC_MAP[key])\n",
    "    \n",
    "    # Specific case for 'g', if it was mapped to 'ڭ' and needs to be 'غ' or 'ج'\n",
    "    # For now, 'ڭ' is kept, and normalize_arabic can handle it.\n",
    "    # If user specifically wants 'g' -> 'غ', then ARABIZI_TO_ARABIC_MAP['g'] = 'غ'\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_arabic_text(text: str) -> str:\n",
    "    \"\"\"Normalizes Arabic script.\"\"\"\n",
    "    # Remove diacritics (tashkeel)\n",
    "    text = re.sub(r'[\\u064B-\\u065F\\u0670]', '', text)\n",
    "    # Remove tatweel (ـ)\n",
    "    text = text.replace('\\u0640', '')\n",
    "    \n",
    "    # Normalize Alef forms to plain Alef (ا)\n",
    "    text = text.replace('أ', 'ا').replace('إ', 'ا').replace('آ', 'ا').replace('ٱ', 'ا')\n",
    "    \n",
    "    # Normalize common variants\n",
    "    text = text.replace('ة', 'ه')  # Ta marbuta to Ha\n",
    "    text = text.replace('ى', 'ي')  # Alef maksura to Ya\n",
    "    \n",
    "    # Normalize Perso-Arabic letters to common Arabic equivalents if desired\n",
    "    text = text.replace('گ', 'ك')  # Persian Gaf to Kaf\n",
    "    text = text.replace('ڭ', 'ك')  # Moroccan Gaf (if produced by arabize_text) to Kaf. Or map to ج or غ if preferred.\n",
    "                                  # Let's map ڭ to ك as it's a common normalization.\n",
    "    text = text.replace('چ', 'ش')  # Cheh to Shin (if 'ch' was mapped to 'چ')\n",
    "    text = text.replace('پ', 'ب')  # Peh to Ba\n",
    "    text = text.replace('ڤ', 'ف')  # Veh to Fa\n",
    "        \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Word2Vec model from: /teamspace/studios/this_studio/darija_word2vec_bpe_sg_ns.model\n",
      "Word2Vec model loaded successfully.\n",
      "\n",
      "--- Darija Word Similarity Finder (No BPE) ---\n",
      "Type a word or phrase (Darija in Arabic/Latin script, or French) and press Enter.\n",
      "Type 'exit' or 'quit' to close.\n",
      "Original input: 'syara'\n",
      "Processed words: سيارا\n",
      "\n",
      "Top 5 most similar words to 'سيارا':\n",
      "1. ياهياتين        (Score: 0.3318)\n",
      "2. سيوجيبايليي     (Score: 0.3273)\n",
      "3. خطيريين         (Score: 0.3188)\n",
      "4. ووتفففبي        (Score: 0.3104)\n",
      "5. زومم            (Score: 0.3089)\n",
      "Original input: '7rb'\n",
      "Processed words: حرب\n",
      "\n",
      "Top 5 most similar words to 'حرب':\n",
      "1. عليك            (Score: 0.9970)\n",
      "2. بارك            (Score: 0.9970)\n",
      "3. عليهم           (Score: 0.9970)\n",
      "4. تشوفو           (Score: 0.9970)\n",
      "5. الحق            (Score: 0.9969)\n",
      "Original input: 'bark'\n",
      "Processed words: بارك\n",
      "\n",
      "Top 5 most similar words to 'بارك':\n",
      "1. عليك            (Score: 0.9997)\n",
      "2. مبروك           (Score: 0.9996)\n",
      "3. شاء             (Score: 0.9996)\n",
      "4. فيكم            (Score: 0.9996)\n",
      "5. انشاء           (Score: 0.9996)\n",
      "Original input: 'dwla'\n",
      "Processed words: دولا\n",
      "\n",
      "Top 5 most similar words to 'دولا':\n",
      "1. ديففادنافيس     (Score: 0.3358)\n",
      "2. ساييميفينوس     (Score: 0.3332)\n",
      "3. ليسيدس          (Score: 0.3238)\n",
      "4. هتتبستسوكحت     (Score: 0.3216)\n",
      "5. عاشاب           (Score: 0.3197)\n",
      "Exiting...\n"
     ]
    }
   ],
   "source": [
    "word2vec_model = None\n",
    "model_loaded_successfully = False\n",
    "\n",
    "try:\n",
    "    if os.path.exists(WORD2VEC_MODEL_PATH):\n",
    "        print(f\"Loading Word2Vec model from: {WORD2VEC_MODEL_PATH}\")\n",
    "        word2vec_model = Word2Vec.load(WORD2VEC_MODEL_PATH)\n",
    "        print(\"Word2Vec model loaded successfully.\")\n",
    "        model_loaded_successfully = True\n",
    "    else:\n",
    "        print(f\"Error: Word2Vec model file not found at {WORD2VEC_MODEL_PATH}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred during model loading: {e}\")\n",
    "\n",
    "\n",
    "def preprocess_input_phrase_no_bpe(text: str) -> list[str]:\n",
    "    \"\"\"\n",
    "    Applies necessary preprocessing to a single input word/phrase\n",
    "    and returns a list of processed words.\n",
    "    Assumes clean_text_initial, arabize_text, normalize_arabic_text are defined.\n",
    "    \"\"\"\n",
    "    # 1. Initial clean\n",
    "    try:\n",
    "        processed_text = clean_text_initial(text)\n",
    "    except NameError:\n",
    "        print(\"Error: `clean_text_initial` function is not defined. Please define it in a cell above.\")\n",
    "        return []\n",
    "    \n",
    "    # 2. Arabize if it contains Latin characters or Arabizi numbers\n",
    "    if re.search(r'[a-zA-Z0-9]', processed_text):\n",
    "        try:\n",
    "            processed_text = arabize_text(processed_text.lower())\n",
    "        except NameError:\n",
    "            print(\"Error: `arabize_text` function (and `ARABIZI_TO_ARABIC_MAP`) is not defined. Please define it.\")\n",
    "            return []\n",
    "\n",
    "    # 3. Normalize Arabic script\n",
    "    try:\n",
    "        processed_text = normalize_arabic_text(processed_text)\n",
    "    except NameError:\n",
    "        print(\"Error: `normalize_arabic_text` function is not defined. Please define it.\")\n",
    "        return []\n",
    "\n",
    "    # 4. Final minimal clean (remove anything not Arabic or whitespace)\n",
    "    #    and split into words.\n",
    "    processed_text = re.sub(r'[^\\p{Arabic}\\s]', '', processed_text, flags=re.UNICODE)\n",
    "    processed_text = re.sub(r'\\s+', ' ', processed_text).strip()\n",
    "\n",
    "    if not processed_text:\n",
    "        return []\n",
    "\n",
    "    # 5. Split into words\n",
    "    words = processed_text.split()\n",
    "    return words\n",
    "\n",
    "\n",
    "def display_arabic(text: str) -> str:\n",
    "    \"\"\"Helper function to display Arabic text correctly in RTL terminals/outputs.\"\"\"\n",
    "    if RTL_DISPLAY_AVAILABLE:\n",
    "        # return get_display(arabic_reshaper.reshape(text))\n",
    "        pass\n",
    "    return text\n",
    "\n",
    "\n",
    "# --- Main Interaction Loop ---\n",
    "if model_loaded_successfully:\n",
    "    print(\"\\n--- Darija Word Similarity Finder (No BPE) ---\")\n",
    "    print(\"Type a word or phrase (Darija in Arabic/Latin script, or French) and press Enter.\")\n",
    "    print(\"Type 'exit' or 'quit' to close.\")\n",
    "\n",
    "    while True:\n",
    "        try:\n",
    "            user_input = input(\"\\nEnter word or phrase: \").strip()\n",
    "\n",
    "            if not user_input:\n",
    "                continue\n",
    "            if user_input.lower() in ['exit', 'quit']:\n",
    "                print(\"Exiting...\")\n",
    "                break\n",
    "\n",
    "            print(f\"Original input: '{user_input}'\")\n",
    "\n",
    "            # Preprocess the input to get a list of words\n",
    "            input_words = preprocess_input_phrase_no_bpe(user_input)\n",
    "            \n",
    "            if not input_words:\n",
    "                print(\"Input became empty after preprocessing or resulted in no words.\")\n",
    "                continue\n",
    "\n",
    "            print(f\"Processed words: {', '.join([display_arabic(w) for w in input_words])}\")\n",
    "\n",
    "            # Filter out words not in Word2Vec vocabulary\n",
    "            # Note: Word2Vec models usually don't have a specific \"[UNK]\" token unless you add one.\n",
    "            # They simply don't include OOV words in their vocabulary.\n",
    "            valid_words_for_model = [\n",
    "                word for word in input_words \n",
    "                if word in word2vec_model.wv\n",
    "            ]\n",
    "\n",
    "            if not valid_words_for_model:\n",
    "                print(f\"None of the processed words ({', '.join([display_arabic(w) for w in input_words])}) are in the Word2Vec model's vocabulary.\")\n",
    "                print(\"This might happen if the word(s) are very rare or out-of-domain.\")\n",
    "                continue\n",
    "            \n",
    "            if len(valid_words_for_model) < len(input_words):\n",
    "                print(f\"Note: Some words were Out-Of-Vocabulary (OOV) and were excluded from similarity search.\")\n",
    "                print(f\"Using valid words for similarity: {', '.join([display_arabic(w) for w in valid_words_for_model])}\")\n",
    "\n",
    "\n",
    "            # Get similar words from Word2Vec model\n",
    "            # If multiple valid_words_for_model, gensim averages their vectors.\n",
    "            similar_items = word2vec_model.wv.most_similar(positive=valid_words_for_model, topn=5)\n",
    "\n",
    "            print(f\"\\nTop 5 most similar words to '{display_arabic(' '.join(valid_words_for_model))}':\")\n",
    "            if similar_items:\n",
    "                for i, (word, score) in enumerate(similar_items):\n",
    "                    print(f\"{i+1}. {display_arabic(word):<15} (Score: {score:.4f})\")\n",
    "            else:\n",
    "                print(\"No similar words found.\")\n",
    "\n",
    "        except KeyError as e: # Should be rare if we check `word in word2vec_model.wv`\n",
    "            print(f\"Error: One of the processed words '{e}' was not found in the model's vocabulary (unexpected).\")\n",
    "        except NameError as e:\n",
    "            print(f\"Error: A preprocessing function might be missing. {e}. Please define it in a cell above.\")\n",
    "            break # Stop the loop if core functions are missing\n",
    "        except Exception as e:\n",
    "            print(f\"An unexpected error occurred: {e}\")\n",
    "            import traceback\n",
    "            traceback.print_exc()\n",
    "\n",
    "else:\n",
    "    print(\"\\nCannot start similarity finder: Word2Vec model not loaded or core preprocessing functions are missing.\")\n",
    "    print(\"Please ensure the path to the model is correct and preprocessing functions are defined in cells above.\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
